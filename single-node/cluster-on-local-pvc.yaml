#################################################################################################################
# Define the settings for the rook-ceph cluster with common settings for a production cluster on top of bare metal.

# This example expects three nodes, each with two available disks. Please modify it according to your environment.
# See the documentation for more details on storage settings available.

# For example, to create the cluster:
#   kubectl create -f crds.yaml -f common.yaml -f operator.yaml
#   kubectl create -f cluster-on-local-pvc.yaml
#################################################################################################################
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: local0-0
spec:
  storageClassName: local-storage
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  # PV for mon must be a filesystem volume.
  volumeMode: Filesystem
  local:
    # If you want to use dm devices like logical volume, please replace `/dev/sdb` with their device names like `/dev/vg-name/lv-name`.
    path: /dev/vdg
    # path: /dev/vg1/lv1
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - minikube
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: local0-1
spec:
  storageClassName: local-storage
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  # PV for OSD must be a block volume.
  volumeMode: Block
  local:
    path: /dev/vdb
    # path: /dev/vg1/lv2
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - minikube
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: local1-0
spec:
  storageClassName: local-storage
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  volumeMode: Filesystem
  local:
    path: /dev/vdc
    #path: /dev/vg1/lv3
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - minikube
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: local1-1
spec:
  storageClassName: local-storage
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  volumeMode: Block
  local:
    path: /dev/vdd
    # path: /dev/vg1/lv4
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - minikube
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: local2-0
spec:
  storageClassName: local-storage
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  volumeMode: Filesystem
  local:
    path: /dev/vde
    # path: /dev/vg1/lv5
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - minikube
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: local2-1
spec:
  storageClassName: local-storage
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  volumeMode: Block
  local:
    path: /dev/vdf
    # path: /dev/vg1/lv6
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - minikube
---
apiVersion: ceph.rook.io/v1
kind: CephCluster
metadata:
  name: rook-ceph
  namespace: rook-ceph
spec:
  security:
    # Settings to enable key rotation for KEK(Key Encryption Key).
    # Currently, this is supported only for the default encryption type,
    # using kubernetes secrets.
    keyRotation:
      enabled: true
      # The schedule, written in [cron format](https://en.wikipedia.org/wiki/Cron),
      # with which key rotation [CronJob](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/)
      # is created. The default value is `"@weekly"`.
      schedule: "@monthly"
    # To enable the KMS configuration properly don't forget to uncomment the Secret at the end of the file
    kms:
      # name of the config map containing all the kms connection details
      connectionDetails:
        KMS_PROVIDER: "vault"
        VAULT_ADDR: http://vault.default.svc.cluster.local:8200 # e,g: https://vault.my-domain.com:8200
        VAULT_BACKEND_PATH: "rook"
        VAULT_SECRET_ENGINE: "kv-v2"
      # name of the secret containing the kms authentication token
      tokenSecretName: rook-vault-token
  dataDirHostPath: /var/lib/rook
  mon:
    count: 3
    allowMultiplePerNode: true
    volumeClaimTemplate:
      spec:
        storageClassName: local-storage
        resources:
          requests:
            storage: 10Gi
  cephVersion:
    image: quay.io/guits/ceph-volume:bs-rdr
    # image: quay.io/ceph/ceph:v17.2.6
    # image: quay.ceph.io/ceph-ci/ceph:wip-aclamk-os-bluestore-rdr-quincy
    allowUnsupported: true
  skipUpgradeChecks: false
  continueUpgradeAfterChecksEvenIfNotHealthy: false
  mgr:
    count: 1
    modules:
      - name: pg_autoscaler
        enabled: true
  dashboard:
    enabled: true
    ssl: true
  crashCollector:
    disable: false
  storage:
    # store: 
    #   type: bluestore
    storageClassDeviceSets:
      - name: set1
        count: 3
        portable: false
        tuneDeviceClass: true
        tuneFastDeviceClass: false
        encrypted: true
        # placement:
        #   topologySpreadConstraints:
        #     - maxSkew: 1
        #       topologyKey: kubernetes.io/hostname
        #       whenUnsatisfiable: ScheduleAnyway
        #       labelSelector:
        #         matchExpressions:
        #           - key: app
        #             operator: In
        #             values:
        #               - rook-ceph-osd
        #               - rook-ceph-osd-prepare
        # preparePlacement:
        #   podAntiAffinity:
        #     preferredDuringSchedulingIgnoredDuringExecution:
        #       - weight: 100
        #         podAffinityTerm:
        #           labelSelector:
        #             matchExpressions:
        #               - key: app
        #                 operator: In
        #                 values:
        #                   - rook-ceph-osd
        #               - key: app
        #                 operator: In
        #                 values:
        #                   - rook-ceph-osd-prepare
        #           topologyKey: kubernetes.io/hostname
        resources:
        # These are the OSD daemon limits. For OSD prepare limits, see the separate section below for "prepareosd" resources
        #   limits:
        #     cpu: "500m"
        #     memory: "4Gi"
        #   requests:
        #     cpu: "500m"
        #     memory: "4Gi"
        volumeClaimTemplates:
          - metadata:
              name: data
              # if you are looking at giving your OSD a different CRUSH device class than the one detected by Ceph
              # annotations:
              #   crushDeviceClass: hybrid
            spec:
              resources:
                requests:
                  storage: 10Gi
              # IMPORTANT: Change the storage class depending on your environment
              storageClassName: local-storage
              volumeMode: Block
              accessModes:
                - ReadWriteOnce
    # when onlyApplyOSDPlacement is false, will merge both placement.All() and storageClassDeviceSets.Placement
    onlyApplyOSDPlacement: false
  resources:
  #  prepareosd:
  #    limits:
  #      cpu: "200m"
  #      memory: "200Mi"
  #   requests:
  #      cpu: "200m"
  #      memory: "200Mi"
  priorityClassNames:
    mon: system-node-critical
    osd: system-node-critical
    mgr: system-cluster-critical
  disruptionManagement:
    managePodBudgets: true
    osdMaintenanceTimeout: 30
    pgHealthCheckTimeout: 0

---
apiVersion: v1
kind: Secret
metadata:
  name: rook-vault-token
  namespace: rook-ceph # namespace:cluster
data:
  token: aHZzLkNBRVNJSko5c2Y3VWtObFZLY0VweVlxQVVfNWdpZnFEY3VIWTg5SS1qemtFQ2xGb0doNEtIR2gyY3k1U01VaFNUMHRSTTBSRGIxVktUM0E0UWxwNGR6RXphR3c=
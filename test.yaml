apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2023-08-23T04:35:39Z"
  generateName: rook-ceph-osd-0-568dd5db8f-
  labels:
    app: rook-ceph-osd
    app.kubernetes.io/component: cephclusters.ceph.rook.io
    app.kubernetes.io/created-by: rook-ceph-operator
    app.kubernetes.io/instance: "0"
    app.kubernetes.io/managed-by: rook-ceph-operator
    app.kubernetes.io/name: ceph-osd
    app.kubernetes.io/part-of: rook-ceph
    ceph-osd-id: "0"
    ceph.rook.io/DeviceSet: set1
    ceph.rook.io/pvc: set1-data-04z9gd
    ceph_daemon_id: "0"
    ceph_daemon_type: osd
    device-class: hdd
    failure-domain: minikube-m03
    osd: "0"
    osd-store: bluestore
    pod-template-hash: 568dd5db8f
    portable: "false"
    rook.io/operator-namespace: rook-ceph
    rook_cluster: rook-ceph
    topology-location-host: minikube-m03
    topology-location-root: default
  name: rook-ceph-osd-0-568dd5db8f-q6l95
  namespace: rook-ceph
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: ReplicaSet
    name: rook-ceph-osd-0-568dd5db8f
    uid: e9c1153d-1ee3-4614-9fd2-c82ea2bd6cc9
  resourceVersion: "2863"
  uid: 11f7cc09-f684-4ded-9dd4-5b28e178ca7a
spec:
  affinity: {}
  containers:
  - args:
    - --foreground
    - --id
    - "0"
    - --fsid
    - feeac90a-1031-4580-a3ce-0c6cb572663c
    - --setuser
    - ceph
    - --setgroup
    - ceph
    - --crush-location=root=default host=minikube-m03
    - --osd-recovery-sleep=0.1
    - --osd-snap-trim-sleep=2
    - --osd-delete-sleep=2
    - --default-log-to-stderr=true
    - --default-err-to-stderr=true
    - --default-mon-cluster-log-to-stderr=true
    - '--default-log-stderr-prefix=debug '
    - --default-log-to-file=false
    - --default-mon-cluster-log-to-file=false
    - --ms-learn-addr-from-peer=false
    command:
    - ceph-osd
    env:
    - name: ROOK_NODE_NAME
      value: minikube-m03
    - name: ROOK_CLUSTER_ID
      value: 44fcf408-c6df-4006-825b-302ce0405edc
    - name: ROOK_CLUSTER_NAME
      value: rook-ceph
    - name: ROOK_PRIVATE_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: ROOK_PUBLIC_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: POD_NAMESPACE
      value: rook-ceph
    - name: ROOK_MON_ENDPOINTS
      valueFrom:
        configMapKeyRef:
          key: data
          name: rook-ceph-mon-endpoints
    - name: ROOK_CONFIG_DIR
      value: /var/lib/rook
    - name: ROOK_CEPH_CONFIG_OVERRIDE
      value: /etc/rook/config/override.conf
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName
    - name: ROOK_CRUSHMAP_ROOT
      value: default
    - name: ROOK_CRUSHMAP_HOSTNAME
    - name: CEPH_VOLUME_DEBUG
      value: "1"
    - name: CEPH_VOLUME_SKIP_RESTORECON
      value: "1"
    - name: DM_DISABLE_UDEV
      value: "1"
    - name: CONTAINER_IMAGE
      value: quay.io/guits/ceph-volume:bs-rdr
    - name: POD_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.name
    - name: POD_MEMORY_LIMIT
      valueFrom:
        resourceFieldRef:
          divisor: "0"
          resource: limits.memory
    - name: POD_MEMORY_REQUEST
      valueFrom:
        resourceFieldRef:
          divisor: "0"
          resource: requests.memory
    - name: POD_CPU_LIMIT
      valueFrom:
        resourceFieldRef:
          divisor: "1"
          resource: limits.cpu
    - name: POD_CPU_REQUEST
      valueFrom:
        resourceFieldRef:
          divisor: "0"
          resource: requests.cpu
    - name: CEPH_USE_RANDOM_NONCE
      value: "true"
    - name: ROOK_OSD_UUID
      value: c7410303-c11d-4628-8634-5c986dae6bf9
    - name: ROOK_OSD_ID
      value: "0"
    - name: ROOK_CEPH_MON_HOST
      valueFrom:
        secretKeyRef:
          key: mon_host
          name: rook-ceph-config
    - name: CEPH_ARGS
      value: -m $(ROOK_CEPH_MON_HOST)
    - name: ROOK_BLOCK_PATH
      value: /dev/mapper/ceph-c7410303-c11d-4628-8634-5c986dae6bf9-vdc-block-dmcrypt
    - name: ROOK_CV_MODE
      value: raw
    - name: ROOK_OSD_DEVICE_CLASS
      value: hdd
    - name: ROOK_POD_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: ROOK_OSD_PVC_SIZE
      value: 10Gi
    - name: ROOK_PVC_BACKED_OSD
      value: "true"
    envFrom:
    - configMapRef:
        name: rook-ceph-osd-env-override
        optional: true
    image: quay.io/guits/ceph-volume:bs-rdr
    imagePullPolicy: IfNotPresent
    livenessProbe:
      exec:
        command:
        - env
        - -i
        - sh
        - -c
        - |-
          outp="$(ceph --admin-daemon /run/ceph/ceph-osd.0.asok status 2>&1)"
          rc=$?
          if [ $rc -ne 0 ]; then
            echo "ceph daemon health check failed with the following output:"
            echo "$outp" | sed -e 's/^/> /g'
            exit $rc
          fi
      failureThreshold: 3
      initialDelaySeconds: 10
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    name: osd
    resources: {}
    securityContext:
      privileged: true
      readOnlyRootFilesystem: false
      runAsUser: 0
    startupProbe:
      exec:
        command:
        - env
        - -i
        - sh
        - -c
        - |-
          outp="$(ceph --admin-daemon /run/ceph/ceph-osd.0.asok status 2>&1)"
          rc=$?
          if [ $rc -ne 0 ]; then
            echo "ceph daemon health check failed with the following output:"
            echo "$outp" | sed -e 's/^/> /g'
            exit $rc
          fi
      failureThreshold: 720
      initialDelaySeconds: 10
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/lib/rook
      name: rook-data
    - mountPath: /etc/ceph
      name: rook-config-override
      readOnly: true
    - mountPath: /run/ceph
      name: ceph-daemons-sock-dir
    - mountPath: /var/log/ceph
      name: rook-ceph-log
    - mountPath: /var/lib/ceph/crash
      name: rook-ceph-crash
    - mountPath: /run/udev
      name: run-udev
    - mountPath: /dev/mapper
      name: dev-mapper
    - mountPath: /var/lib/ceph/osd/ceph-0
      name: set1-data-04z9gd-bridge
      subPath: ceph-0
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-8gwjx
      readOnly: true
    workingDir: /var/log/ceph
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  hostIPC: true
  initContainers:
  - command:
    - /bin/bash
    - -c
    - "\nset -xe\n\nPVC_SOURCE=/set1-data-04z9gd\nPVC_DEST=/var/lib/ceph/osd/ceph-0/block-tmp\nCP_ARGS=(--archive
      --dereference --verbose)\n\nif [ -b \"$PVC_DEST\" ]; then\n\tPVC_SOURCE_MAJ_MIN=$(stat
      --format '%t%T' $PVC_SOURCE)\n\tPVC_DEST_MAJ_MIN=$(stat --format '%t%T' $PVC_DEST)\n\tif
      [[ \"$PVC_SOURCE_MAJ_MIN\" == \"$PVC_DEST_MAJ_MIN\" ]]; then\n\t\techo \"PVC
      $PVC_DEST already exists and has the same major and minor as $PVC_SOURCE: \"$PVC_SOURCE_MAJ_MIN\"\"\n\t\texit
      0\n\telse\n\t\techo \"PVC's source major/minor numbers changed\"\n\t\tCP_ARGS+=(--remove-destination)\n\tfi\nfi\n\ncp
      \"${CP_ARGS[@]}\" \"$PVC_SOURCE\" \"$PVC_DEST\"\n"
    image: quay.io/guits/ceph-volume:bs-rdr
    imagePullPolicy: IfNotPresent
    name: blkdevmapper
    resources: {}
    securityContext:
      capabilities:
        add:
        - MKNOD
      privileged: false
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeDevices:
    - devicePath: /set1-data-04z9gd
      name: set1-data-04z9gd
    volumeMounts:
    - mountPath: /var/lib/ceph/osd/ceph-0
      name: set1-data-04z9gd-bridge
      subPath: ceph-0
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-8gwjx
      readOnly: true
  - command:
    - /bin/bash
    - -c
    - "\nset -xe\n\nCEPH_FSID=feeac90a-1031-4580-a3ce-0c6cb572663c\nPVC_NAME=set1-data-04z9gd\nKEY_FILE_PATH=/etc/ceph/luks_key\nBLOCK_PATH=/var/lib/ceph/osd/ceph-0/block-tmp\nDM_NAME=set1-data-04z9gd-block-dmcrypt\nDM_PATH=/dev/mapper/set1-data-04z9gd-block-dmcrypt\n\n#
      Helps debugging\ndmsetup version\n\nfunction open_encrypted_block {\n\techo
      \"Opening encrypted device $BLOCK_PATH at $DM_PATH\"\n\tcryptsetup luksOpen
      --verbose --disable-keyring --allow-discards --key-file \"$KEY_FILE_PATH\" \"$BLOCK_PATH\"
      \"$DM_NAME\"\n\trm -f \"$KEY_FILE_PATH\"\n}\n\n# This is done for upgraded clusters
      that did not have the subsystem and label set by the prepare job\nfunction set_luks_subsystem_and_label
      {\n\techo \"setting LUKS label and subsystem\"\n\tcryptsetup config $BLOCK_PATH
      --subsystem ceph_fsid=\"$CEPH_FSID\" --label pvc_name=\"$PVC_NAME\"\n}\n\nif
      [ -b \"$DM_PATH\" ]; then\n\techo \"Encrypted device $BLOCK_PATH already opened
      at $DM_PATH\"\n\tfor field in $(dmsetup table \"$DM_NAME\"); do\n\t\tif [[ \"$field\"
      =~ ^[0-9]+\\:[0-9]+ ]]; then\n\t\t\tunderlaying_block=\"/sys/dev/block/$field\"\n\t\t\tif
      [ ! -d \"$underlaying_block\" ]; then\n\t\t\t\techo \"Underlying block device
      $underlaying_block of crypt $DM_NAME disappeared!\"\n\t\t\t\techo \"Removing
      stale dm device $DM_NAME\"\n\t\t\t\tdmsetup remove --force \"$DM_NAME\"\n\t\t\t\topen_encrypted_block\n\t\t\tfi\n\t\tfi\n\tdone\nelse\n\topen_encrypted_block\nfi\n\n#
      Setting label and subsystem on LUKS1 is not supported and the command will fail\nif
      cryptsetup luksDump $BLOCK_PATH|grep -qEs \"Version:.*2\"; then\n\tset_luks_subsystem_and_label\nelse\n\techo
      \"LUKS version is not 2 so not setting label and subsystem\"\nfi\n"
    image: quay.io/guits/ceph-volume:bs-rdr
    imagePullPolicy: IfNotPresent
    name: encryption-open
    resources: {}
    securityContext:
      privileged: true
      runAsUser: 0
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/lib/ceph/osd/ceph-0
      name: set1-data-04z9gd-bridge
      subPath: ceph-0
    - mountPath: /dev/mapper
      name: dev-mapper
    - mountPath: /etc/ceph
      name: osd-encryption-key
      readOnly: true
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-8gwjx
      readOnly: true
  - command:
    - /bin/bash
    - -c
    - "\nset -xe\n\nPVC_SOURCE=/dev/mapper/set1-data-04z9gd-block-dmcrypt\nPVC_DEST=/var/lib/ceph/osd/ceph-0/block\nCP_ARGS=(--archive
      --dereference --verbose)\n\nif [ -b \"$PVC_DEST\" ]; then\n\tPVC_SOURCE_MAJ_MIN=$(stat
      --format '%t%T' $PVC_SOURCE)\n\tPVC_DEST_MAJ_MIN=$(stat --format '%t%T' $PVC_DEST)\n\tif
      [[ \"$PVC_SOURCE_MAJ_MIN\" == \"$PVC_DEST_MAJ_MIN\" ]]; then\n\t\techo \"PVC
      $PVC_DEST already exists and has the same major and minor as $PVC_SOURCE: \"$PVC_SOURCE_MAJ_MIN\"\"\n\t\texit
      0\n\telse\n\t\techo \"PVC's source major/minor numbers changed\"\n\t\tCP_ARGS+=(--remove-destination)\n\tfi\nfi\n\ncp
      \"${CP_ARGS[@]}\" \"$PVC_SOURCE\" \"$PVC_DEST\"\n"
    image: quay.io/guits/ceph-volume:bs-rdr
    imagePullPolicy: IfNotPresent
    name: blkdevmapper-encryption
    resources: {}
    securityContext:
      capabilities:
        add:
        - MKNOD
      privileged: false
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/lib/ceph/osd/ceph-0
      name: set1-data-04z9gd-bridge
      subPath: ceph-0
    - mountPath: /dev/mapper
      name: dev-mapper
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-8gwjx
      readOnly: true
  - args:
    - --verbose
    - status
    - set1-data-04z9gd-block-dmcrypt
    command:
    - cryptsetup
    image: quay.io/guits/ceph-volume:bs-rdr
    imagePullPolicy: IfNotPresent
    name: encrypted-block-status
    resources: {}
    securityContext:
      privileged: true
      runAsUser: 0
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/lib/ceph/osd/ceph-0
      name: set1-data-04z9gd-bridge
      subPath: ceph-0
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-8gwjx
      readOnly: true
  - args:
    - --verbose
    - resize
    - set1-data-04z9gd-block-dmcrypt
    command:
    - cryptsetup
    image: quay.io/guits/ceph-volume:bs-rdr
    imagePullPolicy: IfNotPresent
    name: expand-encrypted-bluefs
    resources: {}
    securityContext:
      privileged: true
      runAsUser: 0
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/lib/ceph/osd/ceph-0
      name: set1-data-04z9gd-bridge
      subPath: ceph-0
    - mountPath: /dev/mapper
      name: dev-mapper
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-8gwjx
      readOnly: true
  - args:
    - prime-osd-dir
    - --dev
    - /var/lib/ceph/osd/ceph-0/block
    - --path
    - /var/lib/ceph/osd/ceph-0
    - --no-mon-config
    command:
    - ceph-bluestore-tool
    image: quay.io/guits/ceph-volume:bs-rdr
    imagePullPolicy: IfNotPresent
    name: activate
    resources: {}
    securityContext:
      privileged: true
      runAsUser: 0
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeDevices:
    - devicePath: /var/lib/ceph/osd/ceph-0/block
      name: set1-data-04z9gd
    volumeMounts:
    - mountPath: /var/lib/ceph/osd/ceph-0
      name: set1-data-04z9gd-bridge
      subPath: ceph-0
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-8gwjx
      readOnly: true
  - args:
    - bluefs-bdev-expand
    - --path
    - /var/lib/ceph/osd/ceph-0
    command:
    - ceph-bluestore-tool
    image: quay.io/guits/ceph-volume:bs-rdr
    imagePullPolicy: IfNotPresent
    name: expand-bluefs
    resources: {}
    securityContext:
      privileged: true
      runAsUser: 0
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/lib/ceph/osd/ceph-0
      name: set1-data-04z9gd-bridge
      subPath: ceph-0
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-8gwjx
      readOnly: true
  - args:
    - --verbose
    - --recursive
    - ceph:ceph
    - /var/log/ceph
    - /var/lib/ceph/crash
    - /run/ceph
    - /var/lib/ceph/osd/ceph-0
    command:
    - chown
    image: quay.io/guits/ceph-volume:bs-rdr
    imagePullPolicy: IfNotPresent
    name: chown-container-data-dir
    resources: {}
    securityContext:
      privileged: true
      readOnlyRootFilesystem: false
      runAsUser: 0
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/lib/rook
      name: rook-data
    - mountPath: /etc/ceph
      name: rook-config-override
      readOnly: true
    - mountPath: /run/ceph
      name: ceph-daemons-sock-dir
    - mountPath: /var/log/ceph
      name: rook-ceph-log
    - mountPath: /var/lib/ceph/crash
      name: rook-ceph-crash
    - mountPath: /run/udev
      name: run-udev
    - mountPath: /dev/mapper
      name: dev-mapper
    - mountPath: /var/lib/ceph/osd/ceph-0
      name: set1-data-04z9gd-bridge
      subPath: ceph-0
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-8gwjx
      readOnly: true
  nodeName: minikube-m03
  nodeSelector:
    kubernetes.io/hostname: minikube-m03
  preemptionPolicy: PreemptLowerPriority
  priority: 2000001000
  priorityClassName: system-node-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: rook-ceph-osd
  serviceAccountName: rook-ceph-osd
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - emptyDir: {}
    name: rook-data
  - name: rook-config-override
    projected:
      defaultMode: 420
      sources:
      - configMap:
          items:
          - key: config
            mode: 292
            path: ceph.conf
          name: rook-config-override
  - hostPath:
      path: /var/lib/rook/exporter
      type: DirectoryOrCreate
    name: ceph-daemons-sock-dir
  - hostPath:
      path: /var/lib/rook/rook-ceph/log
      type: ""
    name: rook-ceph-log
  - hostPath:
      path: /var/lib/rook/rook-ceph/crash
      type: ""
    name: rook-ceph-crash
  - name: set1-data-04z9gd
    persistentVolumeClaim:
      claimName: set1-data-04z9gd
  - hostPath:
      path: /var/lib/rook/rook-ceph/set1-data-04z9gd
      type: DirectoryOrCreate
    name: set1-data-04z9gd-bridge
  - name: osd-encryption-key
    secret:
      defaultMode: 256
      items:
      - key: dmcrypt-key
        path: luks_key
      secretName: rook-ceph-osd-encryption-key-set1-data-04z9gd
  - hostPath:
      path: /run/udev
      type: ""
    name: run-udev
  - hostPath:
      path: /dev/mapper
      type: ""
    name: dev-mapper
  - name: kube-api-access-8gwjx
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2023-08-23T04:35:53Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2023-08-23T04:36:10Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2023-08-23T04:36:10Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2023-08-23T04:35:39Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: docker://fdcd442f9184d1036d5f33afd3025348fa82cc8ae640138c6369361716d1c7ce
    image: quay.io/guits/ceph-volume:bs-rdr
    imageID: docker://sha256:f3a755dfc14736b33da3ced2b59822124db42d4333ab9443c245c581a655f354
    lastState: {}
    name: osd
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2023-08-23T04:35:53Z"
  hostIP: 192.168.39.37
  initContainerStatuses:
  - containerID: docker://02ecc9e5b717e1eb837f20ac17b0511ea662a4aa10d261e835cba519ab2b360e
    image: quay.io/guits/ceph-volume:bs-rdr
    imageID: docker://sha256:f3a755dfc14736b33da3ced2b59822124db42d4333ab9443c245c581a655f354
    lastState: {}
    name: blkdevmapper
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: docker://02ecc9e5b717e1eb837f20ac17b0511ea662a4aa10d261e835cba519ab2b360e
        exitCode: 0
        finishedAt: "2023-08-23T04:35:40Z"
        reason: Completed
        startedAt: "2023-08-23T04:35:40Z"
  - containerID: docker://7e9d28ab918f4b764b20f3a9b1ec38f52da3acaa06f84caeea7ac8692a4612b7
    image: quay.io/guits/ceph-volume:bs-rdr
    imageID: docker://sha256:f3a755dfc14736b33da3ced2b59822124db42d4333ab9443c245c581a655f354
    lastState: {}
    name: encryption-open
    ready: true
    restartCount: 1
    state:
      terminated:
        containerID: docker://7e9d28ab918f4b764b20f3a9b1ec38f52da3acaa06f84caeea7ac8692a4612b7
        exitCode: 0
        finishedAt: "2023-08-23T04:35:44Z"
        reason: Completed
        startedAt: "2023-08-23T04:35:44Z"
  - containerID: docker://bfe004a3dcc5e021f32d267b106c802f0f1838cbe63e73fad63bd256b2958939
    image: quay.io/guits/ceph-volume:bs-rdr
    imageID: docker://sha256:f3a755dfc14736b33da3ced2b59822124db42d4333ab9443c245c581a655f354
    lastState: {}
    name: blkdevmapper-encryption
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: docker://bfe004a3dcc5e021f32d267b106c802f0f1838cbe63e73fad63bd256b2958939
        exitCode: 0
        finishedAt: "2023-08-23T04:35:46Z"
        reason: Completed
        startedAt: "2023-08-23T04:35:46Z"
  - containerID: docker://b0ffa5b6122eac2e6e3de4415c938cbe1e5f96814b6df47f37f169e3ab2b2cc0
    image: quay.io/guits/ceph-volume:bs-rdr
    imageID: docker://sha256:f3a755dfc14736b33da3ced2b59822124db42d4333ab9443c245c581a655f354
    lastState: {}
    name: encrypted-block-status
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: docker://b0ffa5b6122eac2e6e3de4415c938cbe1e5f96814b6df47f37f169e3ab2b2cc0
        exitCode: 0
        finishedAt: "2023-08-23T04:35:46Z"
        reason: Completed
        startedAt: "2023-08-23T04:35:46Z"
  - containerID: docker://02434aec20da0618d7bd7ed26215284d535bc020f89c10608fe29bf2f05b8aec
    image: quay.io/guits/ceph-volume:bs-rdr
    imageID: docker://sha256:f3a755dfc14736b33da3ced2b59822124db42d4333ab9443c245c581a655f354
    lastState: {}
    name: expand-encrypted-bluefs
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: docker://02434aec20da0618d7bd7ed26215284d535bc020f89c10608fe29bf2f05b8aec
        exitCode: 0
        finishedAt: "2023-08-23T04:35:47Z"
        reason: Completed
        startedAt: "2023-08-23T04:35:47Z"
  - containerID: docker://8fb09d46450efb32148c90e566e26f1fec01b4c20a0536a7aeb593fdc03c6f2a
    image: quay.io/guits/ceph-volume:bs-rdr
    imageID: docker://sha256:f3a755dfc14736b33da3ced2b59822124db42d4333ab9443c245c581a655f354
    lastState: {}
    name: activate
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: docker://8fb09d46450efb32148c90e566e26f1fec01b4c20a0536a7aeb593fdc03c6f2a
        exitCode: 0
        finishedAt: "2023-08-23T04:35:49Z"
        reason: Completed
        startedAt: "2023-08-23T04:35:49Z"
  - containerID: docker://bf4a9a6bf4c9fc458ec4619013b2f8b61b2c929282f4f779f409d54e03dcfbbd
    image: quay.io/guits/ceph-volume:bs-rdr
    imageID: docker://sha256:f3a755dfc14736b33da3ced2b59822124db42d4333ab9443c245c581a655f354
    lastState: {}
    name: expand-bluefs
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: docker://bf4a9a6bf4c9fc458ec4619013b2f8b61b2c929282f4f779f409d54e03dcfbbd
        exitCode: 0
        finishedAt: "2023-08-23T04:35:51Z"
        reason: Completed
        startedAt: "2023-08-23T04:35:50Z"
  - containerID: docker://496d040b9620e5e4ced65c6db5a355e2a1fb70218e0b8506eb611240abd34df4
    image: quay.io/guits/ceph-volume:bs-rdr
    imageID: docker://sha256:f3a755dfc14736b33da3ced2b59822124db42d4333ab9443c245c581a655f354
    lastState: {}
    name: chown-container-data-dir
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: docker://496d040b9620e5e4ced65c6db5a355e2a1fb70218e0b8506eb611240abd34df4
        exitCode: 0
        finishedAt: "2023-08-23T04:35:52Z"
        reason: Completed
        startedAt: "2023-08-23T04:35:52Z"
  phase: Running
  podIP: 10.244.2.9
  podIPs:
  - ip: 10.244.2.9
  qosClass: BestEffort
  startTime: "2023-08-23T04:35:39Z"
